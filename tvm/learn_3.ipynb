{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "\n",
    "import tvm\n",
    "from tvm import relay\n",
    "\n",
    "onnx_model_path = '/home/pre-learn/onnx_runtime/model.onnx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = onnx.load_model(onnx_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as onnxrt\n",
    "\n",
    "sess_options = onnxrt.SessionOptions()\n",
    "sess = onnxrt.InferenceSession(\n",
    "        model.SerializeToString(),\n",
    "        sess_options=sess_options,\n",
    "        providers=onnxrt.get_available_providers(),\n",
    "    )\n",
    "meta = sess.get_modelmeta()\n",
    "\n",
    "input_name = sess.get_inputs()[0].name\n",
    "# shape_list = [(input_name, sess.get_inputs()[0].shape)]\n",
    "shape = sess.get_inputs()[0].shape\n",
    "shape[0] = 1\n",
    "shape_list = {input_name:shape}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conv2d_input': [1, 28, 28, 1]}\n"
     ]
    }
   ],
   "source": [
    "print(shape_list)\n",
    "mod,params = relay.frontend.from_onnx(model,shape_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    intrp = relay.build_module.create_executor(\"graph\", mod, tvm.cpu(0), target='llvm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dtype = \"float32\"\n",
    "\n",
    "out = intrp.evaluate()(tvm.nd.array(np.random.uniform(size=shape).astype(dtype)),**params).asnumpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'llvm'\n",
    "target_host = target\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    lib = relay.build(mod, target=target, target_host=target_host,params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116 µs ± 13.1 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "import tvm.contrib.graph_executor as runtime\n",
    "\n",
    "test_data = np.random.uniform(size=shape).astype(dtype)\n",
    "ctx = tvm.cpu(0)\n",
    "m = runtime.GraphModule(lib['default'](ctx))\n",
    "\n",
    "def bench_tvm():\n",
    "    m.set_input(input_name, tvm.nd.array(test_data))\n",
    "    m.run()\n",
    "\n",
    "%timeit bench_tvm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147 µs ± 1.69 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def bench_ort():\n",
    "    sess.run(None, {input_name: test_data})\n",
    "\n",
    "%timeit bench_ort()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
